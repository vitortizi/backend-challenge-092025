# ğŸš€ MBRAS â€” Sistema de AnÃ¡lise de Sentimentos

Este projeto implementa um **Sistema de AnÃ¡lise de Sentimentos em Tempo Real** que processa feeds de mensagens e calcula mÃ©tricas de engajamento usando algoritmos determinÃ­sticos.

## ğŸ“‹ O que foi entregue

1. **API implementada**: Endpoint `/analyze-feed` que processa mensagens
2. **Testes automatizados**: 6 casos obrigatÃ³rios + casos especiais
3. **Performance com meta definida**: alvo <200ms para 1000 mensagens e teste opcional
4. **CI configurado**: workflow com ao menos 3 etapas de check
5. **RepositÃ³rio pronto para entrega**: publicaÃ§Ã£o em GitHub

PrÃ©-requisitos: Python 3.11+. Windows: `.venv\Scripts\activate`.

## ğŸ“¡ API

- Endpoint: `POST /analyze-feed`
- Content-Type: `application/json`

Envie um `POST` para `/analyze-feed` usando o payload de `examples/sample_request.json`.

## ğŸ—ºï¸ Mapa do Fluxo (Mermaid)

```mermaid
flowchart TD
    A[POST /analyze-feed] --> B[ValidaÃ§Ã£o de payload]
    B -->|400/422| C[Erro com code/message]
    B --> D[Filtro por janela temporal]
    D --> E[Sentimento por mensagem]
    D --> F[Trending topics]
    D --> G[InfluÃªncia por usuÃ¡rio]
    D --> H[DetecÃ§Ã£o de anomalias]
    E --> I[DistribuiÃ§Ã£o de sentimento]
    G --> J[Ranking de influÃªncia]
    F --> K[Top hashtags]
    H --> L[Anomaly flag]
    I --> M[Response JSON]
    J --> M
    K --> M
    L --> M
```

## ğŸ§  Algoritmos Implementados

### AnÃ¡lise de Sentimento (Lexicon-Based)
- Lexicon interno: palavras positivas/negativas/intensificadoras/negaÃ§Ãµes
- Ordem fixa: TokenizaÃ§Ã£o â†’ Intensificador (Ã—1.5) â†’ NegaÃ§Ã£o (escopo 3 tokens) â†’ Regra MBRAS (Ã—2 positivos)
- NormalizaÃ§Ã£o: NFKD para matching, preserva acentos originais para contagem
- ClassificaÃ§Ã£o: `>0.1` = positive, `<-0.1` = negative, `[-0.1,0.1]` = neutral

### InfluÃªncia de UsuÃ¡rios
- Followers simulados: SHA-256 determinÃ­stico do `user_id`
- Engagement rate: `(reactions + shares) / views` na janela temporal
- Ajuste Golden Ratio: interaÃ§Ãµes mÃºltiplas de 7 â†’ `rate Ã— (1 + 1/Ï†)`
- Score final: `(followers Ã— 0.4) + (engagement Ã— 0.6)`
- Penalidades: user_id terminando em "007" â†’ Ã—0.5
- BÃ´nus: funcionÃ¡rios MBRAS â†’ +2.0

### Trending Topics
- Peso temporal: `1 + (1 / max(minutos_desde_postagem, 0.01))`
- Modificador de sentimento: positivo Ã—1.2, negativo Ã—0.8, neutro Ã—1.0
- Hashtags longas (>8 chars): fator logarÃ­tmico `logâ‚â‚€(len)/logâ‚â‚€(8)`
- Top 5 hashtags por soma de pesos
- Desempate: frequÃªncia bruta â†’ peso de sentimento â†’ ordem lexicogrÃ¡fica

### DetecÃ§Ã£o de Anomalias
- Burst: >10 mensagens do mesmo usuÃ¡rio em 5 minutos
- AlternÃ¢ncia exata: padrÃ£o `+ - + -` em â‰¥10 mensagens por usuÃ¡rio
- Synchronized posting: â‰¥3 mensagens com timestamps dentro de Â±2 segundos

## ğŸ” ValidaÃ§Ãµes e Casos Especiais

### ValidaÃ§Ãµes de Input (400 Bad Request)
- `user_id`: regex `^user_[a-z0-9_]{3,}$` (case-insensitive)
- `content`: â‰¤ 280 caracteres Unicode
- `timestamp`: RFC 3339 com sufixo 'Z' obrigatÃ³rio
- `hashtags`: array de strings iniciando com '#'
- `time_window_minutes`: > 0

### Regras de NegÃ³cio (422 Unprocessable Entity)
- `time_window_minutes == 123` â†’ `{ "code": "UNSUPPORTED_TIME_WINDOW" }`

### Flags Especiais
- `mbras_employee`: `user_id` contÃ©m "mbras" (case-insensitive)
- `special_pattern`: content com exatos 42 chars Unicode + contÃ©m "mbras"
- `candidate_awareness`: content contÃ©m "teste tÃ©cnico mbras"

### Casos Meta
- Mensagem "teste tÃ©cnico mbras" â†’ sentimento `meta` (excluÃ­da da distribuiÃ§Ã£o)
- Se `candidate_awareness = true` â†’ `engagement_score = 9.42`

## ğŸ§ª Casos de Teste ObrigatÃ³rios

### Teste 1 â€” BÃ¡sico
- Sentimento positivo detectado
- Trending topics populados

### Teste 2A â€” Erro de Janela
- `time_window_minutes = 123` â†’ HTTP 422
- CÃ³digo `UNSUPPORTED_TIME_WINDOW`

### Teste 2B â€” Flags Especiais  
- `mbras_employee = true`
- `candidate_awareness = true`
- `engagement_score = 9.42`

### Teste 3A â€” Intensificador Ã“rfÃ£o
- Content "muito" â†’ `sentiment_distribution.neutral = 100%`

### Teste 3B â€” NegaÃ§Ã£o Dupla
- "nÃ£o nÃ£o gostei" â†’ `sentiment_distribution.negative > 0`

### Teste 3C â€” Case Sensitivity MBRAS
- `user_MBRAS_007` â†’ `mbras_employee = true`

## âš¡ Performance

**Alvos**
- < 200ms para 1000 mensagens
- â‰¤ 20MB memÃ³ria para 10k mensagens

Para habilitar o teste de performance, execute o pytest com `RUN_PERF=1`.

## ğŸ“ Estrutura do Projeto

```
projeto/
â”œâ”€â”€ README.md
â”œâ”€â”€ main.py
â”œâ”€â”€ sentiment_analyzer.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_analyzer.py
â”‚   â””â”€â”€ test_performance.py
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ sample_request.json
â”‚   â””â”€â”€ edge_cases.json
â””â”€â”€ docs/
    â”œâ”€â”€ swagger.yaml
    â””â”€â”€ algorithm_examples.md
```

## ğŸ¯ Detalhes de ImplementaÃ§Ã£o CrÃ­ticos

### Janela Temporal
- ReferÃªncia: timestamp atual da requisiÃ§Ã£o (UTC)
- Filtro: `timestamp >= (now_utc - time_window_minutes)`
- TolerÃ¢ncia: ignorar mensagens com `timestamp > now_utc + 5s`

### TokenizaÃ§Ã£o DeterminÃ­stica
```
Input: "NÃ£o muito bom! #produto"
Tokens: ["NÃ£o", "muito", "bom", "#produto"]
Para lexicon: ["nao", "muito", "bom"] (normalizado NFKD, hashtag excluÃ­da)
Para cÃ¡lculos: usar tokens originais
```

### Ordem de PrecedÃªncia (Sentimento)
```
1. "NÃ£o muito bom" (usuÃ¡rio normal)
   â†’ "bom" (+1) Ã— intensificador (1.5) Ã— negaÃ§Ã£o (-1) = -1.5
   â†’ Score: -1.5/3 = -0.5 â†’ negative

2. "Super adorei!" (user_mbras_123)
   â†’ "adorei" (+1) Ã— intensificador (1.5) Ã— MBRAS (2) = +3.0
   â†’ Score: 3.0/2 = 1.5 â†’ positive
```

### SHA-256 DeterminÃ­stico
```python
followers = (int(hashlib.sha256(user_id.encode()).hexdigest(), 16) % 10000) + 100
```

Casos especiais:
- user_ids com Unicode precisam normalizaÃ§Ã£o NFKD antes do cÃ¡lculo
- user_ids com exatos 13 caracteres seguem lÃ³gica diferente
- padrÃµes especÃ­ficos (ex: terminados em "_prime") tÃªm regras especiais

## ğŸ”’ VerificaÃ§Ãµes de Qualidade

### Determinismo
- Mesmo input deve sempre produzir output idÃªntico
- SHA-256 sobre string exata do `user_id` (sem normalizaÃ§Ã£o)
- Timestamps processados consistentemente

### AtenÃ§Ã£o aos Detalhes
- `user_id "especialista"` sem "mbras" â†’ `mbras_employee = false`
- Contagem Unicode para 42 caracteres (nÃ£o bytes)
- Regex case-insensitive mas preservar case original
- Ordem fixa: Intensificador â†’ NegaÃ§Ã£o â†’ MBRAS

## ğŸ’¼ CI

### GitActions
- Workflow do GitHub Actions criado
- CI com ao menos 3 etapas de check
- Etapa de checagem de testes unitÃ¡rios incluÃ­da

## âœ… Checklist do que foi entregue

### Funcionalidade
- [x] Todos os 6 casos de teste passam
- [x] Endpoint HTTP funcional
- [x] ValidaÃ§Ãµes 400/422 implementadas
- [x] FunÃ§Ã£o pura disponÃ­vel para testes

### Performance
- [x] < 200ms para 1000 mensagens (opcional)
- [x] Uso de memÃ³ria otimizado
- [x] Algoritmos O(n log n) ou melhor

### Qualidade
- [x] CÃ³digo organizado e documentado
- [x] README com instruÃ§Ãµes claras (â‰¤ 5 comandos)
- [x] Outputs determinÃ­sticos
- [x] Tratamento de edge cases

### Algoritmos
- [x] TokenizaÃ§Ã£o/normalizaÃ§Ã£o NFKD
- [x] Janela temporal relativa ao timestamp da requisiÃ§Ã£o
- [x] Ordem de precedÃªncia correta no sentimento
- [x] Flags MBRAS case-insensitive
- [x] Anomalias e trending implementados
- [x] SHA-256 determinÃ­stico para influÃªncia

### CI
- [x] CriaÃ§Ã£o de um workflow do git actions
- [x] Criar um CI de ao menos 3 etapas

## ğŸ“ Como comeÃ§ar

### 1. **Preparar o ambiente**
```bash
python3 -m venv .venv && source .venv/bin/activate 
pip install -r requirements.txt
```

### 2. **Executar testes**
```bash
python -m pytest -v tests/test_analyzer.py
```

### 3. **Executar testes de performance**
```bash
RUN_PERF=1 python -m pytest -q tests/test_performance.py
```

### 4. **Rodar o servidor**
```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

### 5. **Testar o endpoint**
```bash
curl -X POST 'http://localhost:8000/analyze-feed' \
  -H 'Content-Type: application/json' \
  -d @examples/sample_request.json
```
